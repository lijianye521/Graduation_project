{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'input_ids': tensor([[32573,   247, 42468, 31660, 10310,   103,   160,   122,   233, 36310,\n",
      "         16764, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256,\n",
      "         50256, 50256],\n",
      "        [32573,   247, 42468, 31660, 10310,   103,   162,   249,   112,   165,\n",
      "           243,   123, 21410,   160,   122,   233, 36310, 23877,   229, 17312,\n",
      "           105, 16764]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}\n"
     ]
    }
   ],
   "source": [
    "#test 不用管\n",
    "from transformers import GPT2Tokenizer, GPT2Model\n",
    "\n",
    "# 加载分词器\n",
    "tokenizer = GPT2Tokenizer.from_pretrained('gpt2')\n",
    "\n",
    "# 设置pad_token为eos_token，因为GPT-2默认没有pad_token\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "\n",
    "# 示例文本\n",
    "texts = [\"这是一个例子。\", \"这是一个更长的例子文本。\"]\n",
    "\n",
    "# 使用分词器处理文本，启用填充\n",
    "inputs = tokenizer(texts, padding=True, return_tensors=\"pt\")\n",
    "\n",
    "# inputs现在包含了填充后的input_ids和attention_mask，可以直接用于模型\n",
    "print(inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "from tqdm.auto import tqdm\n",
    "import warnings\n",
    "from transformers import BertTokenizer, BertForSequenceClassification, AdamW\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch.utils.data import DataLoader, RandomSampler, SequentialSampler, TensorDataset\n",
    "import pandas as pd\n",
    "\n",
    "# 忽略特定的警告\n",
    "warnings.filterwarnings(\"ignore\", message=\"Be aware, overflowing tokens are not returned*\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " the number of label is 170\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Administrator\\AppData\\Local\\Temp\\ipykernel_5748\\2693177685.py:10: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  df['label'] = df['developer'].replace(label_dict).infer_objects()\n"
     ]
    }
   ],
   "source": [
    "# 加载数据\n",
    "new_file_path = './dataset2/OpenOffice_total_10_10.csv'\n",
    "# 指定需要提取的列\n",
    "columns_to_extract = ['bug_id', 'product', 'abstracts', 'description', 'component', 'severity', 'priority', 'developer',  'status']\n",
    "# columns_to_extract = [ 'description', 'developer']\n",
    "df = pd.read_csv(new_file_path, usecols=columns_to_extract, encoding='latin-1')\n",
    "# 将developer列作为标签\n",
    "label_dict = {label: idx for idx, label in enumerate(df['developer'].unique())}\n",
    "print(f' the number of label is {len(label_dict)}')\n",
    "df['label'] = df['developer'].replace(label_dict).infer_objects()\n",
    "# 合并bug_id和summary作为模型的输入\n",
    "df['text_input'] = df['abstracts'].astype(str) + \" \" + df['description'].astype(str)  # 使用空格作为分隔符\n",
    "X_train, X_val, y_train, y_val = train_test_split(df.index.values, df.label.values, test_size=0.15, random_state=42, stratify=df.label.values)\n",
    "df['data_type'] = ['not_set']*df.shape[0]\n",
    "df.loc[X_train, 'data_type'] = 'train'\n",
    "df.loc[X_val, 'data_type'] = 'val'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 对训练和验证数据的合并文本进行编码\n",
    "encoded_data_train = tokenizer.batch_encode_plus(\n",
    "    df[df.data_type=='train'].text_input.values,  # 使用合并后的文本\n",
    "    add_special_tokens=True, \n",
    "    return_attention_mask=True, \n",
    "    padding='max_length',  # 更新pad_to_max_length为padding\n",
    "    max_length=512, \n",
    "    truncation=True,  # 明确启用截断\n",
    "    return_tensors='pt'\n",
    ")\n",
    "\n",
    "encoded_data_val = tokenizer.batch_encode_plus(\n",
    "    df[df.data_type=='val'].text_input.values,  # 使用合并后的文本\n",
    "    add_special_tokens=True, \n",
    "    return_attention_mask=True, \n",
    "    padding='max_length',  # 更新pad_to_max_length为padding\n",
    "    max_length=512, \n",
    "    truncation=True,  # 明确启用截断\n",
    "    return_tensors='pt'\n",
    ")\n",
    "\n",
    "# 准备Tensor数据\n",
    "input_ids_train = encoded_data_train['input_ids']\n",
    "attention_masks_train = encoded_data_train['attention_mask']\n",
    "labels_train = torch.tensor(df[df.data_type=='train'].label.values)\n",
    "\n",
    "input_ids_val = encoded_data_val['input_ids']\n",
    "attention_masks_val = encoded_data_val['attention_mask']\n",
    "labels_val = torch.tensor(df[df.data_type=='val'].label.values)\n",
    "\n",
    "dataset_train = TensorDataset(input_ids_train, attention_masks_train, labels_train)\n",
    "dataset_val = TensorDataset(input_ids_val, attention_masks_val, labels_val)\n",
    "\n",
    "# 定义DataLoader\n",
    "batch_size = 2\n",
    "train_loader = DataLoader(dataset_train, sampler=RandomSampler(dataset_train), batch_size=batch_size)\n",
    "val_loader = DataLoader(dataset_val, sampler=SequentialSampler(dataset_val), batch_size=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 初始化gpt2模型\n",
    "# device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# # model = BertForSequenceClassification.from_pretrained(\"bert-base-uncased\", num_labels=len(label_dict), output_attentions=False, output_hidden_states=False)\n",
    "# from transformers import GPT2Tokenizer, GPT2ForSequenceClassification,GPT2Config\n",
    "# # 感谢外国诱人stackoverflow帮我解决的bug\n",
    "# # instantiate the configuration for your model, this can be imported from transformers\n",
    "# configuration = GPT2Config()\n",
    "# # set up your tokenizer, just like you described, and set the pad token\n",
    "# GPT2_tokenizer = GPT2Tokenizer.from_pretrained(\"gpt2\")\n",
    "# # instantiate the model\n",
    "# model_name=\"gpt2\"\n",
    "\n",
    "# model = GPT2ForSequenceClassification(configuration).from_pretrained(model_name).to(device)\n",
    "# # set the pad token of the model's configuration\n",
    "# model.config.pad_token_id = model.config.eos_token_id\n",
    "# model.resize_token_embeddings(len(tokenizer))\n",
    "\n",
    "# optimizer = AdamW(model.parameters(), lr=1e-5, eps=1e-8)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of GPT2ForSequenceClassification were not initialized from the model checkpoint at gpt2 and are newly initialized: ['score.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "c:\\ProgramData\\anaconda3\\envs\\django5\\lib\\site-packages\\transformers\\optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import GPT2Tokenizer, GPT2ForSequenceClassification, GPT2Config, AdamW\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# 确保这里使用的是正确的分词器变量名\n",
    "GPT2_tokenizer = GPT2Tokenizer.from_pretrained(\"gpt2\")\n",
    "# 设置pad_token为eos_token\n",
    "GPT2_tokenizer.pad_token = GPT2_tokenizer.eos_token\n",
    "\n",
    "# 通过GPT2Config设置num_labels参数\n",
    "num_labels = len(label_dict)  # 请替换为实际的标签数量\n",
    "configuration = GPT2Config.from_pretrained(\"gpt2\", num_labels=num_labels)\n",
    "\n",
    "model = GPT2ForSequenceClassification.from_pretrained(\"gpt2\", config=configuration).to(device)\n",
    "# 设置模型的pad_token_id\n",
    "#感谢stackoverflow\n",
    "model.config.pad_token_id = GPT2_tokenizer.pad_token_id\n",
    "# 使用GPT2_tokenizer的长度来调整模型的token embeddings大小\n",
    "model.resize_token_embeddings(len(GPT2_tokenizer))\n",
    "\n",
    "optimizer = AdamW(model.parameters(), lr=1e-5, eps=1e-8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "# from transformers import BertTokenizer\n",
    "\n",
    "# # 加载新的数据集\n",
    "# new_file_path = './data_开发者阈值10_词频阈值10/Mozilla_total_10_10.csv'\n",
    "# columns_to_extract = ['bug_id', 'product', 'abstracts', 'description', 'component', 'severity', 'priority', 'history', 'status']\n",
    "# df = pd.read_csv(new_file_path, usecols=columns_to_extract, encoding='latin-1')\n",
    "\n",
    "# # 合并文本信息为模型的输入，除了developer列\n",
    "# df['text_input'] = df[['bug_id', 'product', 'abstracts', 'description', 'component', 'severity', 'priority', 'history', 'status']].astype(str).agg(' '.join, axis=1)\n",
    "\n",
    "# tokenizer = BertTokenizer.from_pretrained('bert-base-uncased', do_lower_case=True)\n",
    "\n",
    "# # 对所有合并后的文本进行编码\n",
    "# encoded_inputs = tokenizer.batch_encode_plus(df['text_input'].tolist(), add_special_tokens=True, truncation=True, padding=False, max_length=512)\n",
    "\n",
    "# # 计算所有编码后的长度\n",
    "# lengths = [len(input_ids) for input_ids in encoded_inputs['input_ids']]\n",
    "\n",
    "# # 计算平均长度、中位数、最大和最小长度\n",
    "# average_length = sum(lengths) / len(lengths)\n",
    "# median_length = sorted(lengths)[len(lengths) // 2]\n",
    "# max_length = max(lengths)\n",
    "# min_length = min(lengths)\n",
    "\n",
    "# print(f\"Average length: {average_length}\")\n",
    "# print(f\"Median length: {median_length}\")\n",
    "# print(f\"Max length: {max_length}\")\n",
    "# print(f\"Min length: {min_length}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resuming training from epoch 1\n"
     ]
    }
   ],
   "source": [
    "\n",
    "model.to(device)\n",
    "\n",
    "checkpoint_path = 'model_xuezhang——ne44t.pth'\n",
    "\n",
    "# 检查是否有可用的检查点\n",
    "if os.path.isfile(checkpoint_path):\n",
    "    checkpoint = torch.load(checkpoint_path)\n",
    "    model.load_state_dict(checkpoint['model_state_dict'])\n",
    "    optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "    start_epoch = checkpoint['epoch'] + 1\n",
    "    print(f'Resuming training from epoch {start_epoch}')\n",
    "else:\n",
    "    start_epoch = 0\n",
    "    print('Starting training from scratch')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "85ac8be6d30243648d0928c0e71e81a9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 2:   0%|          | 0/8783 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9f31aa02e5494963b20251d5a98e5b0e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating:   0%|          | 0/1551 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy after epoch 2: Top1: 36.54%\n",
      "[36.53660109642051]\n",
      "Accuracy after epoch 2: Top2: 48.66%\n",
      "[36.53660109642051, 48.661722025153175]\n",
      "Accuracy after epoch 2: Top3: 56.37%\n",
      "[36.53660109642051, 48.661722025153175, 56.3689132537891]\n",
      "Accuracy after epoch 2: Top4: 61.08%\n",
      "[36.53660109642051, 48.661722025153175, 56.3689132537891, 61.07707191228636]\n",
      "Accuracy after epoch 2: Top5: 64.21%\n",
      "[36.53660109642051, 48.661722025153175, 56.3689132537891, 61.07707191228636, 64.20509513060303]\n",
      "Accuracy after epoch 2: Top6: 66.49%\n",
      "[36.53660109642051, 48.661722025153175, 56.3689132537891, 61.07707191228636, 64.20509513060303, 66.49467913576265]\n",
      "Accuracy after epoch 2: Top7: 68.88%\n",
      "[36.53660109642051, 48.661722025153175, 56.3689132537891, 61.07707191228636, 64.20509513060303, 66.49467913576265, 68.88100612705578]\n",
      "Accuracy after epoch 2: Top8: 70.85%\n",
      "[36.53660109642051, 48.661722025153175, 56.3689132537891, 61.07707191228636, 64.20509513060303, 66.49467913576265, 68.88100612705578, 70.84811351177039]\n",
      "Accuracy after epoch 2: Top9: 72.46%\n",
      "[36.53660109642051, 48.661722025153175, 56.3689132537891, 61.07707191228636, 64.20509513060303, 66.49467913576265, 68.88100612705578, 70.84811351177039, 72.46049661399549]\n",
      "Accuracy after epoch 2: Top10: 73.75%\n",
      "[36.53660109642051, 48.661722025153175, 56.3689132537891, 61.07707191228636, 64.20509513060303, 66.49467913576265, 68.88100612705578, 70.84811351177039, 72.46049661399549, 73.75040309577555]\n",
      "Epoch 2 training data inserted into train.csv.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2f5acc76efdc4408a823441b3542a08a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 3:   0%|          | 0/8783 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eb283f09d4e64cd7ba1e804dcf814e1e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating:   0%|          | 0/1551 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy after epoch 3: Top1: 39.73%\n",
      "[39.729119638826184]\n",
      "Accuracy after epoch 3: Top2: 52.37%\n",
      "[39.729119638826184, 52.37020316027088]\n",
      "Accuracy after epoch 3: Top3: 59.79%\n",
      "[39.729119638826184, 52.37020316027088, 59.78716543050629]\n",
      "Accuracy after epoch 3: Top4: 64.17%\n",
      "[39.729119638826184, 52.37020316027088, 59.78716543050629, 64.17284746855853]\n",
      "Accuracy after epoch 3: Top5: 66.95%\n",
      "[39.729119638826184, 52.37020316027088, 59.78716543050629, 64.17284746855853, 66.94614640438569]\n",
      "Accuracy after epoch 3: Top6: 69.40%\n",
      "[39.729119638826184, 52.37020316027088, 59.78716543050629, 64.17284746855853, 66.94614640438569, 69.39696871976781]\n",
      "Accuracy after epoch 3: Top7: 71.27%\n",
      "[39.729119638826184, 52.37020316027088, 59.78716543050629, 64.17284746855853, 66.94614640438569, 69.39696871976781, 71.26733311834892]\n",
      "Accuracy after epoch 3: Top8: 72.75%\n",
      "[39.729119638826184, 52.37020316027088, 59.78716543050629, 64.17284746855853, 66.94614640438569, 69.39696871976781, 71.26733311834892, 72.75072557239601]\n",
      "Accuracy after epoch 3: Top9: 74.23%\n",
      "[39.729119638826184, 52.37020316027088, 59.78716543050629, 64.17284746855853, 66.94614640438569, 69.39696871976781, 71.26733311834892, 72.75072557239601, 74.23411802644308]\n",
      "Accuracy after epoch 3: Top10: 75.43%\n",
      "[39.729119638826184, 52.37020316027088, 59.78716543050629, 64.17284746855853, 66.94614640438569, 69.39696871976781, 71.26733311834892, 72.75072557239601, 74.23411802644308, 75.42728152208964]\n",
      "Epoch 3 training data inserted into train.csv.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "416f01158c4e444bb050877b0a50a336",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 4:   0%|          | 0/8783 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2cb78da8ad8e4fc08d21479ae0a2398f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating:   0%|          | 0/1551 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy after epoch 4: Top1: 40.02%\n",
      "[40.0193485972267]\n",
      "Accuracy after epoch 4: Top2: 54.40%\n",
      "[40.0193485972267, 54.401805869074494]\n",
      "Accuracy after epoch 4: Top3: 61.34%\n",
      "[40.0193485972267, 54.401805869074494, 61.33505320864237]\n",
      "Accuracy after epoch 4: Top4: 65.79%\n",
      "[40.0193485972267, 54.401805869074494, 61.33505320864237, 65.78523057078363]\n",
      "Accuracy after epoch 4: Top5: 68.46%\n",
      "[40.0193485972267, 54.401805869074494, 61.33505320864237, 65.78523057078363, 68.46178652047726]\n",
      "Accuracy after epoch 4: Top6: 70.69%\n",
      "[40.0193485972267, 54.401805869074494, 61.33505320864237, 65.78523057078363, 68.46178652047726, 70.68687520154789]\n",
      "Accuracy after epoch 4: Top7: 72.62%\n",
      "[40.0193485972267, 54.401805869074494, 61.33505320864237, 65.78523057078363, 68.46178652047726, 70.68687520154789, 72.62173492421799]\n",
      "Accuracy after epoch 4: Top8: 74.11%\n",
      "[40.0193485972267, 54.401805869074494, 61.33505320864237, 65.78523057078363, 68.46178652047726, 70.68687520154789, 72.62173492421799, 74.10512737826508]\n",
      "Accuracy after epoch 4: Top9: 75.04%\n",
      "[40.0193485972267, 54.401805869074494, 61.33505320864237, 65.78523057078363, 68.46178652047726, 70.68687520154789, 72.62173492421799, 74.10512737826508, 75.04030957755563]\n",
      "Accuracy after epoch 4: Top10: 76.36%\n",
      "[40.0193485972267, 54.401805869074494, 61.33505320864237, 65.78523057078363, 68.46178652047726, 70.68687520154789, 72.62173492421799, 74.10512737826508, 75.04030957755563, 76.3624637213802]\n",
      "Epoch 4 training data inserted into train.csv.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bd22ef0d1f8a4ab087529c2497211ff4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 5:   0%|          | 0/8783 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9ec4785991924804abf1d49985b686fd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating:   0%|          | 0/1551 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy after epoch 5: Top1: 41.89%\n",
      "[41.889712995807805]\n",
      "Accuracy after epoch 5: Top2: 53.60%\n",
      "[41.889712995807805, 53.595614317961946]\n",
      "Accuracy after epoch 5: Top3: 61.56%\n",
      "[41.889712995807805, 53.595614317961946, 61.56078684295389]\n",
      "Accuracy after epoch 5: Top4: 66.46%\n",
      "[41.889712995807805, 53.595614317961946, 61.56078684295389, 66.46243147371815]\n",
      "Accuracy after epoch 5: Top5: 69.33%\n",
      "[41.889712995807805, 53.595614317961946, 61.56078684295389, 66.46243147371815, 69.33247339567882]\n",
      "Accuracy after epoch 5: Top6: 71.78%\n",
      "[41.889712995807805, 53.595614317961946, 61.56078684295389, 66.46243147371815, 69.33247339567882, 71.78329571106094]\n",
      "Accuracy after epoch 5: Top7: 73.33%\n",
      "[41.889712995807805, 53.595614317961946, 61.56078684295389, 66.46243147371815, 69.33247339567882, 71.78329571106094, 73.33118348919703]\n",
      "Accuracy after epoch 5: Top8: 74.65%\n",
      "[41.889712995807805, 53.595614317961946, 61.56078684295389, 66.46243147371815, 69.33247339567882, 71.78329571106094, 73.33118348919703, 74.65333763302161]\n",
      "Accuracy after epoch 5: Top9: 75.91%\n",
      "[41.889712995807805, 53.595614317961946, 61.56078684295389, 66.46243147371815, 69.33247339567882, 71.78329571106094, 73.33118348919703, 74.65333763302161, 75.91099645275717]\n",
      "Accuracy after epoch 5: Top10: 77.20%\n",
      "[41.889712995807805, 53.595614317961946, 61.56078684295389, 66.46243147371815, 69.33247339567882, 71.78329571106094, 73.33118348919703, 74.65333763302161, 75.91099645275717, 77.20090293453724]\n",
      "Epoch 5 training data inserted into train.csv.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0a7c0a56947a444ebec5676c9e9c0628",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 6:   0%|          | 0/8783 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3a8de974675a4d1ca1c94b817d3ccdd7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating:   0%|          | 0/1551 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy after epoch 6: Top1: 41.44%\n",
      "[41.43824572718478]\n",
      "Accuracy after epoch 6: Top2: 54.82%\n",
      "[41.43824572718478, 54.821025475653016]\n",
      "Accuracy after epoch 6: Top3: 62.08%\n",
      "[41.43824572718478, 54.821025475653016, 62.07674943566592]\n",
      "Accuracy after epoch 6: Top4: 66.14%\n",
      "[41.43824572718478, 54.821025475653016, 62.07674943566592, 66.13995485327314]\n",
      "Accuracy after epoch 6: Top5: 69.20%\n",
      "[41.43824572718478, 54.821025475653016, 62.07674943566592, 66.13995485327314, 69.2034827475008]\n",
      "Accuracy after epoch 6: Top6: 71.30%\n",
      "[41.43824572718478, 54.821025475653016, 62.07674943566592, 66.13995485327314, 69.2034827475008, 71.29958078039343]\n",
      "Accuracy after epoch 6: Top7: 73.49%\n",
      "[41.43824572718478, 54.821025475653016, 62.07674943566592, 66.13995485327314, 69.2034827475008, 71.29958078039343, 73.49242179941955]\n",
      "Accuracy after epoch 6: Top8: 75.10%\n",
      "[41.43824572718478, 54.821025475653016, 62.07674943566592, 66.13995485327314, 69.2034827475008, 71.29958078039343, 73.49242179941955, 75.10480490164463]\n",
      "Accuracy after epoch 6: Top9: 76.81%\n",
      "[41.43824572718478, 54.821025475653016, 62.07674943566592, 66.13995485327314, 69.2034827475008, 71.29958078039343, 73.49242179941955, 75.10480490164463, 76.81393099000323]\n",
      "Accuracy after epoch 6: Top10: 77.88%\n",
      "[41.43824572718478, 54.821025475653016, 62.07674943566592, 66.13995485327314, 69.2034827475008, 71.29958078039343, 73.49242179941955, 75.10480490164463, 76.81393099000323, 77.87810383747178]\n",
      "Epoch 6 training data inserted into train.csv.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "799c9be3d7fa4a26b9660dbfdf774c3a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 7:   0%|          | 0/8783 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "43c020a9a4c24ab790b4909ebf76978c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating:   0%|          | 0/1551 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy after epoch 7: Top1: 40.37%\n",
      "[40.37407287971622]\n",
      "Accuracy after epoch 7: Top2: 54.43%\n",
      "[40.37407287971622, 54.43405353111899]\n",
      "Accuracy after epoch 7: Top3: 61.17%\n",
      "[40.37407287971622, 54.43405353111899, 61.17381489841986]\n",
      "Accuracy after epoch 7: Top4: 65.62%\n",
      "[40.37407287971622, 54.43405353111899, 61.17381489841986, 65.62399226056111]\n",
      "Accuracy after epoch 7: Top5: 68.49%\n",
      "[40.37407287971622, 54.43405353111899, 61.17381489841986, 65.62399226056111, 68.49403418252177]\n",
      "Accuracy after epoch 7: Top6: 70.72%\n",
      "[40.37407287971622, 54.43405353111899, 61.17381489841986, 65.62399226056111, 68.49403418252177, 70.71912286359239]\n",
      "Accuracy after epoch 7: Top7: 72.49%\n",
      "[40.37407287971622, 54.43405353111899, 61.17381489841986, 65.62399226056111, 68.49403418252177, 70.71912286359239, 72.49274427603999]\n",
      "Accuracy after epoch 7: Top8: 74.04%\n",
      "[40.37407287971622, 54.43405353111899, 61.17381489841986, 65.62399226056111, 68.49403418252177, 70.71912286359239, 72.49274427603999, 74.04063205417607]\n",
      "Accuracy after epoch 7: Top9: 75.46%\n",
      "[40.37407287971622, 54.43405353111899, 61.17381489841986, 65.62399226056111, 68.49403418252177, 70.71912286359239, 72.49274427603999, 74.04063205417607, 75.45952918413415]\n",
      "Accuracy after epoch 7: Top10: 76.52%\n",
      "[40.37407287971622, 54.43405353111899, 61.17381489841986, 65.62399226056111, 68.49403418252177, 70.71912286359239, 72.49274427603999, 74.04063205417607, 75.45952918413415, 76.52370203160271]\n",
      "Epoch 7 training data inserted into train.csv.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bf29683df78845d79ca4ec173140eb01",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 8:   0%|          | 0/8783 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1e96008a9feb499e8a8eda9b71de25a9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating:   0%|          | 0/1551 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy after epoch 8: Top1: 40.83%\n",
      "[40.82554014833924]\n",
      "Accuracy after epoch 8: Top2: 54.47%\n",
      "[40.82554014833924, 54.466301193163495]\n",
      "Accuracy after epoch 8: Top3: 61.59%\n",
      "[40.82554014833924, 54.466301193163495, 61.593034504998386]\n",
      "Accuracy after epoch 8: Top4: 66.08%\n",
      "[40.82554014833924, 54.466301193163495, 61.593034504998386, 66.07545952918413]\n",
      "Accuracy after epoch 8: Top5: 68.69%\n",
      "[40.82554014833924, 54.466301193163495, 61.593034504998386, 66.07545952918413, 68.68752015478877]\n",
      "Accuracy after epoch 8: Top6: 70.62%\n",
      "[40.82554014833924, 54.466301193163495, 61.593034504998386, 66.07545952918413, 68.68752015478877, 70.62237987745888]\n",
      "Accuracy after epoch 8: Top7: 72.91%\n",
      "[40.82554014833924, 54.466301193163495, 61.593034504998386, 66.07545952918413, 68.68752015478877, 70.62237987745888, 72.91196388261851]\n",
      "Accuracy after epoch 8: Top8: 74.65%\n",
      "[40.82554014833924, 54.466301193163495, 61.593034504998386, 66.07545952918413, 68.68752015478877, 70.62237987745888, 72.91196388261851, 74.65333763302161]\n",
      "Accuracy after epoch 8: Top9: 75.98%\n",
      "[40.82554014833924, 54.466301193163495, 61.593034504998386, 66.07545952918413, 68.68752015478877, 70.62237987745888, 72.91196388261851, 74.65333763302161, 75.97549177684618]\n",
      "Accuracy after epoch 8: Top10: 76.91%\n",
      "[40.82554014833924, 54.466301193163495, 61.593034504998386, 66.07545952918413, 68.68752015478877, 70.62237987745888, 72.91196388261851, 74.65333763302161, 75.97549177684618, 76.91067397613674]\n",
      "Epoch 8 training data inserted into train.csv.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3fb0b4c7589947ec9976a8f445dc54ed",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 9:   0%|          | 0/8783 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8a407879170344b3b6931954d52c376b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating:   0%|          | 0/1551 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy after epoch 9: Top1: 40.12%\n",
      "[40.11609158336021]\n",
      "Accuracy after epoch 9: Top2: 52.53%\n",
      "[40.11609158336021, 52.53144147049339]\n",
      "Accuracy after epoch 9: Top3: 59.59%\n",
      "[40.11609158336021, 52.53144147049339, 59.59367945823928]\n",
      "Accuracy after epoch 9: Top4: 64.88%\n",
      "[40.11609158336021, 52.53144147049339, 59.59367945823928, 64.88229603353757]\n",
      "Accuracy after epoch 9: Top5: 68.24%\n",
      "[40.11609158336021, 52.53144147049339, 59.59367945823928, 64.88229603353757, 68.23605288616575]\n",
      "Accuracy after epoch 9: Top6: 70.20%\n",
      "[40.11609158336021, 52.53144147049339, 59.59367945823928, 64.88229603353757, 68.23605288616575, 70.20316027088036]\n",
      "Accuracy after epoch 9: Top7: 71.78%\n",
      "[40.11609158336021, 52.53144147049339, 59.59367945823928, 64.88229603353757, 68.23605288616575, 70.20316027088036, 71.78329571106094]\n",
      "Accuracy after epoch 9: Top8: 73.49%\n",
      "[40.11609158336021, 52.53144147049339, 59.59367945823928, 64.88229603353757, 68.23605288616575, 70.20316027088036, 71.78329571106094, 73.49242179941955]\n",
      "Accuracy after epoch 9: Top9: 74.56%\n",
      "[40.11609158336021, 52.53144147049339, 59.59367945823928, 64.88229603353757, 68.23605288616575, 70.20316027088036, 71.78329571106094, 73.49242179941955, 74.5565946468881]\n",
      "Accuracy after epoch 9: Top10: 76.04%\n",
      "[40.11609158336021, 52.53144147049339, 59.59367945823928, 64.88229603353757, 68.23605288616575, 70.20316027088036, 71.78329571106094, 73.49242179941955, 74.5565946468881, 76.03998710093518]\n",
      "Epoch 9 training data inserted into train.csv.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ee73d1574c0744388ff313bb8343bfc4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 10:   0%|          | 0/8783 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[9], line 31\u001b[0m\n\u001b[0;32m     29\u001b[0m     loss\u001b[38;5;241m.\u001b[39mbackward()\n\u001b[0;32m     30\u001b[0m     optimizer\u001b[38;5;241m.\u001b[39mstep()\n\u001b[1;32m---> 31\u001b[0m     progress_bar\u001b[38;5;241m.\u001b[39mset_postfix(loss\u001b[38;5;241m=\u001b[39m\u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mitem\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[0;32m     32\u001b[0m torch\u001b[38;5;241m.\u001b[39msave({\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mepoch\u001b[39m\u001b[38;5;124m'\u001b[39m: epoch, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmodel_state_dict\u001b[39m\u001b[38;5;124m'\u001b[39m: model\u001b[38;5;241m.\u001b[39mstate_dict(), \u001b[38;5;124m'\u001b[39m\u001b[38;5;124moptimizer_state_dict\u001b[39m\u001b[38;5;124m'\u001b[39m: optimizer\u001b[38;5;241m.\u001b[39mstate_dict()}, checkpoint_path)\n\u001b[0;32m     33\u001b[0m model\u001b[38;5;241m.\u001b[39meval()\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import pymysql\n",
    "from datetime import datetime\n",
    "\n",
    "# 数据库连接信息\n",
    "host = '38.147.173.234'\n",
    "user = 'lijianye'\n",
    "password = '660013'\n",
    "db = 'training_statistics_db'\n",
    "experiment_num = 13\n",
    "# 模型名称，根据实际情况手动设置\n",
    "model_name = 'gpt2'\n",
    "# 学习率和可选特性，根据实际情况手动设置\n",
    "learning_rate = 1e-5  # 示例学习率\n",
    "optional_feature = 'abstract+descrition'  # 示例可选特性\n",
    "dataset = new_file_path\n",
    "num_epochs = 15\n",
    "for epoch in range(start_epoch, num_epochs):\n",
    "    model.train()\n",
    "    start_time = datetime.now()\n",
    "        \n",
    "    progress_bar = tqdm(train_loader, desc=f\"Epoch {epoch + 1}\")\n",
    "    for batch in progress_bar:\n",
    "        optimizer.zero_grad()\n",
    "        input_ids = batch[0].to(device)\n",
    "        attention_mask = batch[1].to(device)\n",
    "        labels = batch[2].to(device)\n",
    "        outputs = model(input_ids, attention_mask=attention_mask, labels=labels)\n",
    "        loss = outputs[0]\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        progress_bar.set_postfix(loss=loss.item())\n",
    "    torch.save({'epoch': epoch, 'model_state_dict': model.state_dict(), 'optimizer_state_dict': optimizer.state_dict()}, checkpoint_path)\n",
    "    model.eval()\n",
    "    correct_topk = {k: 0 for k in range(1, 11)}\n",
    "    total = 0\n",
    "    val_progress_bar = tqdm(val_loader, desc=\"Validating\")\n",
    "    \n",
    "    for batch in val_progress_bar:\n",
    "        input_ids = batch[0].to(device)\n",
    "        attention_mask = batch[1].to(device)\n",
    "        labels = batch[2].to(device)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            outputs = model(input_ids, attention_mask=attention_mask)\n",
    "        logits = outputs[0]\n",
    "        total += labels.size(0)\n",
    "        \n",
    "        # 计算top1到top10的正确率\n",
    "        _, predicted_topk = torch.topk(logits, k=10, dim=1)\n",
    "        labels_expanded = labels.unsqueeze(1)\n",
    "        for k in range(1, 11):\n",
    "            correct_topk[k] += (predicted_topk[:, :k] == labels_expanded).any(dim=1).sum().item()\n",
    "                \n",
    "    # 打印每个topK的准确率\n",
    "    top10accuracy = []  # 初始化存储Top1到Top10准确率的数组\n",
    "\n",
    "    for k in range(1, 11):\n",
    "        accuracy = 100 * correct_topk[k] / total\n",
    "        top10accuracy.append(accuracy)  # 将计算出的准确率添加到数组中\n",
    "        print(f'Accuracy after epoch {epoch + 1}: Top{k}: {accuracy:.2f}%')\n",
    "        print(top10accuracy)\n",
    "    import pandas as pd\n",
    "    import os\n",
    "        # ...训练结束时间\n",
    "    end_time = datetime.now()\n",
    "    duration = (end_time - start_time).total_seconds()/60.0\n",
    "    # 定义数据字典，用于创建DataFrame\n",
    "    data = {\n",
    "            'epoch': [epoch],\n",
    "            'start_time': [start_time],\n",
    "            'end_time': [end_time],\n",
    "            'duration': [duration],\n",
    "            'user_id': [1],\n",
    "            'model': [model_name],\n",
    "            'top1_accuracy': [top10accuracy[0]],\n",
    "            'top2_accuracy': [top10accuracy[1]],\n",
    "            'top3_accuracy': [top10accuracy[2]],\n",
    "            'top4_accuracy': [top10accuracy[3]],\n",
    "            'top5_accuracy': [top10accuracy[4]],\n",
    "            'top6_accuracy': [top10accuracy[5]],\n",
    "            'top7_accuracy': [top10accuracy[6]],\n",
    "            'top8_accuracy': [top10accuracy[7]],\n",
    "            'top9_accuracy': [top10accuracy[8]],\n",
    "            'top10_accuracy': [top10accuracy[9]],\n",
    "            'optional_feature': [optional_feature],\n",
    "            'learning_rate': [learning_rate],\n",
    "            'dataset': [dataset],\n",
    "            'experiment_num':[experiment_num],\n",
    "    }\n",
    "\n",
    "        # 创建DataFrame\n",
    "    df = pd.DataFrame(data)\n",
    "\n",
    "        # 检查train.csv文件是否存在来决定是否添加表头\n",
    "    file_exists = os.path.isfile('modified_train_with_updated_duration.csv')\n",
    "\n",
    "        # 如果文件存在，不写入表头，模式为追加；如果文件不存在，写入表头，模式为写入\n",
    "    df.to_csv('xuezhangtrainoutcome.csv', mode='a', header=not file_exists, index=False)\n",
    "\n",
    "    print(f'Epoch {epoch + 1} training data inserted into train.csv.')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "django5",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
