{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "from tqdm.auto import tqdm\n",
    "import warnings\n",
    "from transformers import BertTokenizer, BertForSequenceClassification, AdamW\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch.utils.data import DataLoader, RandomSampler, SequentialSampler, TensorDataset\n",
    "import pandas as pd\n",
    "import torch\n",
    "from transformers import GPT2Tokenizer, GPT2ForSequenceClassification, GPT2Config, AdamW\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of GPT2ForSequenceClassification were not initialized from the model checkpoint at gpt2 and are newly initialized: ['score.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPT2ForSequenceClassification(\n",
      "  (transformer): GPT2Model(\n",
      "    (wte): Embedding(50257, 768)\n",
      "    (wpe): Embedding(1024, 768)\n",
      "    (drop): Dropout(p=0.1, inplace=False)\n",
      "    (h): ModuleList(\n",
      "      (0-11): 12 x GPT2Block(\n",
      "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "        (attn): GPT2Attention(\n",
      "          (c_attn): Conv1D()\n",
      "          (c_proj): Conv1D()\n",
      "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
      "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "        (mlp): GPT2MLP(\n",
      "          (c_fc): Conv1D()\n",
      "          (c_proj): Conv1D()\n",
      "          (act): NewGELUActivation()\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (ln_f): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "  )\n",
      "  (score): Linear(in_features=768, out_features=2, bias=False)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# model = BertForSequenceClassification.from_pretrained(\"bert-large-uncased\", num_labels=67, output_attentions=False, output_hidden_states=False)\n",
    "model = GPT2ForSequenceClassification.from_pretrained(\"gpt2\" )\n",
    "\n",
    "# 加载模型\n",
    "# 计算层数\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([50257, 1024])\n",
      "torch.Size([2048, 1024])\n",
      "torch.Size([1024])\n",
      "torch.Size([1024])\n",
      "torch.Size([1024, 3072])\n",
      "torch.Size([3072])\n",
      "torch.Size([1024, 1024])\n",
      "torch.Size([1024])\n",
      "torch.Size([1024])\n",
      "torch.Size([1024])\n",
      "torch.Size([1024, 4096])\n",
      "torch.Size([4096])\n",
      "torch.Size([4096, 1024])\n",
      "torch.Size([1024])\n",
      "torch.Size([1024])\n",
      "torch.Size([1024])\n",
      "torch.Size([1024, 3072])\n",
      "torch.Size([3072])\n",
      "torch.Size([1024, 1024])\n",
      "torch.Size([1024])\n",
      "torch.Size([1024])\n",
      "torch.Size([1024])\n",
      "torch.Size([1024, 4096])\n",
      "torch.Size([4096])\n",
      "torch.Size([4096, 1024])\n",
      "torch.Size([1024])\n",
      "torch.Size([1024])\n",
      "torch.Size([1024])\n",
      "torch.Size([1024, 3072])\n",
      "torch.Size([3072])\n",
      "torch.Size([1024, 1024])\n",
      "torch.Size([1024])\n",
      "torch.Size([1024])\n",
      "torch.Size([1024])\n",
      "torch.Size([1024, 4096])\n",
      "torch.Size([4096])\n",
      "torch.Size([4096, 1024])\n",
      "torch.Size([1024])\n",
      "torch.Size([1024])\n",
      "torch.Size([1024])\n",
      "torch.Size([1024, 3072])\n",
      "torch.Size([3072])\n",
      "torch.Size([1024, 1024])\n",
      "torch.Size([1024])\n",
      "torch.Size([1024])\n",
      "torch.Size([1024])\n",
      "torch.Size([1024, 4096])\n",
      "torch.Size([4096])\n",
      "torch.Size([4096, 1024])\n",
      "torch.Size([1024])\n",
      "torch.Size([1024])\n",
      "torch.Size([1024])\n",
      "torch.Size([1024, 3072])\n",
      "torch.Size([3072])\n",
      "torch.Size([1024, 1024])\n",
      "torch.Size([1024])\n",
      "torch.Size([1024])\n",
      "torch.Size([1024])\n",
      "torch.Size([1024, 4096])\n",
      "torch.Size([4096])\n",
      "torch.Size([4096, 1024])\n",
      "torch.Size([1024])\n",
      "torch.Size([1024])\n",
      "torch.Size([1024])\n",
      "torch.Size([1024, 3072])\n",
      "torch.Size([3072])\n",
      "torch.Size([1024, 1024])\n",
      "torch.Size([1024])\n",
      "torch.Size([1024])\n",
      "torch.Size([1024])\n",
      "torch.Size([1024, 4096])\n",
      "torch.Size([4096])\n",
      "torch.Size([4096, 1024])\n",
      "torch.Size([1024])\n",
      "torch.Size([1024])\n",
      "torch.Size([1024])\n",
      "torch.Size([1024, 3072])\n",
      "torch.Size([3072])\n",
      "torch.Size([1024, 1024])\n",
      "torch.Size([1024])\n",
      "torch.Size([1024])\n",
      "torch.Size([1024])\n",
      "torch.Size([1024, 4096])\n",
      "torch.Size([4096])\n",
      "torch.Size([4096, 1024])\n",
      "torch.Size([1024])\n",
      "torch.Size([1024])\n",
      "torch.Size([1024])\n",
      "torch.Size([1024, 3072])\n",
      "torch.Size([3072])\n",
      "torch.Size([1024, 1024])\n",
      "torch.Size([1024])\n",
      "torch.Size([1024])\n",
      "torch.Size([1024])\n",
      "torch.Size([1024, 4096])\n",
      "torch.Size([4096])\n",
      "torch.Size([4096, 1024])\n",
      "torch.Size([1024])\n",
      "torch.Size([1024])\n",
      "torch.Size([1024])\n",
      "torch.Size([1024, 3072])\n",
      "torch.Size([3072])\n",
      "torch.Size([1024, 1024])\n",
      "torch.Size([1024])\n",
      "torch.Size([1024])\n",
      "torch.Size([1024])\n",
      "torch.Size([1024, 4096])\n",
      "torch.Size([4096])\n",
      "torch.Size([4096, 1024])\n",
      "torch.Size([1024])\n",
      "torch.Size([1024])\n",
      "torch.Size([1024])\n",
      "torch.Size([1024, 3072])\n",
      "torch.Size([3072])\n",
      "torch.Size([1024, 1024])\n",
      "torch.Size([1024])\n",
      "torch.Size([1024])\n",
      "torch.Size([1024])\n",
      "torch.Size([1024, 4096])\n",
      "torch.Size([4096])\n",
      "torch.Size([4096, 1024])\n",
      "torch.Size([1024])\n",
      "torch.Size([1024])\n",
      "torch.Size([1024])\n",
      "torch.Size([1024, 3072])\n",
      "torch.Size([3072])\n",
      "torch.Size([1024, 1024])\n",
      "torch.Size([1024])\n",
      "torch.Size([1024])\n",
      "torch.Size([1024])\n",
      "torch.Size([1024, 4096])\n",
      "torch.Size([4096])\n",
      "torch.Size([4096, 1024])\n",
      "torch.Size([1024])\n",
      "torch.Size([1024])\n",
      "torch.Size([1024])\n",
      "torch.Size([1024, 3072])\n",
      "torch.Size([3072])\n",
      "torch.Size([1024, 1024])\n",
      "torch.Size([1024])\n",
      "torch.Size([1024])\n",
      "torch.Size([1024])\n",
      "torch.Size([1024, 4096])\n",
      "torch.Size([4096])\n",
      "torch.Size([4096, 1024])\n",
      "torch.Size([1024])\n",
      "torch.Size([1024])\n",
      "torch.Size([1024])\n",
      "torch.Size([1024, 3072])\n",
      "torch.Size([3072])\n",
      "torch.Size([1024, 1024])\n",
      "torch.Size([1024])\n",
      "torch.Size([1024])\n",
      "torch.Size([1024])\n",
      "torch.Size([1024, 4096])\n",
      "torch.Size([4096])\n",
      "torch.Size([4096, 1024])\n",
      "torch.Size([1024])\n",
      "torch.Size([1024])\n",
      "torch.Size([1024])\n",
      "torch.Size([1024, 3072])\n",
      "torch.Size([3072])\n",
      "torch.Size([1024, 1024])\n",
      "torch.Size([1024])\n",
      "torch.Size([1024])\n",
      "torch.Size([1024])\n",
      "torch.Size([1024, 4096])\n",
      "torch.Size([4096])\n",
      "torch.Size([4096, 1024])\n",
      "torch.Size([1024])\n",
      "torch.Size([1024])\n",
      "torch.Size([1024])\n",
      "torch.Size([1024, 3072])\n",
      "torch.Size([3072])\n",
      "torch.Size([1024, 1024])\n",
      "torch.Size([1024])\n",
      "torch.Size([1024])\n",
      "torch.Size([1024])\n",
      "torch.Size([1024, 4096])\n",
      "torch.Size([4096])\n",
      "torch.Size([4096, 1024])\n",
      "torch.Size([1024])\n",
      "torch.Size([1024])\n",
      "torch.Size([1024])\n",
      "torch.Size([1024, 3072])\n",
      "torch.Size([3072])\n",
      "torch.Size([1024, 1024])\n",
      "torch.Size([1024])\n",
      "torch.Size([1024])\n",
      "torch.Size([1024])\n",
      "torch.Size([1024, 4096])\n",
      "torch.Size([4096])\n",
      "torch.Size([4096, 1024])\n",
      "torch.Size([1024])\n",
      "torch.Size([1024])\n",
      "torch.Size([1024])\n",
      "torch.Size([1024, 3072])\n",
      "torch.Size([3072])\n",
      "torch.Size([1024, 1024])\n",
      "torch.Size([1024])\n",
      "torch.Size([1024])\n",
      "torch.Size([1024])\n",
      "torch.Size([1024, 4096])\n",
      "torch.Size([4096])\n",
      "torch.Size([4096, 1024])\n",
      "torch.Size([1024])\n",
      "torch.Size([1024])\n",
      "torch.Size([1024])\n",
      "torch.Size([1024, 3072])\n",
      "torch.Size([3072])\n",
      "torch.Size([1024, 1024])\n",
      "torch.Size([1024])\n",
      "torch.Size([1024])\n",
      "torch.Size([1024])\n",
      "torch.Size([1024, 4096])\n",
      "torch.Size([4096])\n",
      "torch.Size([4096, 1024])\n",
      "torch.Size([1024])\n",
      "torch.Size([1024])\n",
      "torch.Size([1024])\n",
      "torch.Size([1024, 3072])\n",
      "torch.Size([3072])\n",
      "torch.Size([1024, 1024])\n",
      "torch.Size([1024])\n",
      "torch.Size([1024])\n",
      "torch.Size([1024])\n",
      "torch.Size([1024, 4096])\n",
      "torch.Size([4096])\n",
      "torch.Size([4096, 1024])\n",
      "torch.Size([1024])\n",
      "torch.Size([1024])\n",
      "torch.Size([1024])\n",
      "torch.Size([1024, 3072])\n",
      "torch.Size([3072])\n",
      "torch.Size([1024, 1024])\n",
      "torch.Size([1024])\n",
      "torch.Size([1024])\n",
      "torch.Size([1024])\n",
      "torch.Size([1024, 4096])\n",
      "torch.Size([4096])\n",
      "torch.Size([4096, 1024])\n",
      "torch.Size([1024])\n",
      "torch.Size([1024])\n",
      "torch.Size([1024])\n",
      "torch.Size([1024, 3072])\n",
      "torch.Size([3072])\n",
      "torch.Size([1024, 1024])\n",
      "torch.Size([1024])\n",
      "torch.Size([1024])\n",
      "torch.Size([1024])\n",
      "torch.Size([1024, 4096])\n",
      "torch.Size([4096])\n",
      "torch.Size([4096, 1024])\n",
      "torch.Size([1024])\n",
      "torch.Size([1024])\n",
      "torch.Size([1024])\n",
      "torch.Size([1024, 3072])\n",
      "torch.Size([3072])\n",
      "torch.Size([1024, 1024])\n",
      "torch.Size([1024])\n",
      "torch.Size([1024])\n",
      "torch.Size([1024])\n",
      "torch.Size([1024, 4096])\n",
      "torch.Size([4096])\n",
      "torch.Size([4096, 1024])\n",
      "torch.Size([1024])\n",
      "torch.Size([1024])\n",
      "torch.Size([1024])\n",
      "torch.Size([1024, 3072])\n",
      "torch.Size([3072])\n",
      "torch.Size([1024, 1024])\n",
      "torch.Size([1024])\n",
      "torch.Size([1024])\n",
      "torch.Size([1024])\n",
      "torch.Size([1024, 4096])\n",
      "torch.Size([4096])\n",
      "torch.Size([4096, 1024])\n",
      "torch.Size([1024])\n",
      "torch.Size([1024])\n",
      "torch.Size([1024])\n",
      "torch.Size([1024, 3072])\n",
      "torch.Size([3072])\n",
      "torch.Size([1024, 1024])\n",
      "torch.Size([1024])\n",
      "torch.Size([1024])\n",
      "torch.Size([1024])\n",
      "torch.Size([1024, 4096])\n",
      "torch.Size([4096])\n",
      "torch.Size([4096, 1024])\n",
      "torch.Size([1024])\n",
      "torch.Size([1024])\n",
      "torch.Size([1024])\n",
      "该网络参数总量为： 355871744\n"
     ]
    }
   ],
   "source": [
    "# Load model directly\n",
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"Irina/fantasy_GPT3Medium\")\n",
    "model = AutoModelForCausalLM.from_pretrained(\"Irina/fantasy_GPT3Medium\")\n",
    "param_num = 0\n",
    "for param in model.parameters():\n",
    "    param_num += torch.numel(param)\n",
    "    print(param.shape)\n",
    "print('该网络参数总量为：',param_num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at xlnet-base-cased were not used when initializing XLNetForSequenceClassification: ['lm_loss.weight', 'lm_loss.bias']\n",
      "- This IS expected if you are initializing XLNetForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing XLNetForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of XLNetForSequenceClassification were not initialized from the model checkpoint at xlnet-base-cased and are newly initialized: ['logits_proj.weight', 'sequence_summary.summary.weight', 'logits_proj.bias', 'sequence_summary.summary.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 1, 768])\n",
      "torch.Size([32000, 768])\n",
      "torch.Size([768, 12, 64])\n",
      "torch.Size([768, 12, 64])\n",
      "torch.Size([768, 12, 64])\n",
      "torch.Size([768, 12, 64])\n",
      "torch.Size([768, 12, 64])\n",
      "torch.Size([12, 64])\n",
      "torch.Size([12, 64])\n",
      "torch.Size([12, 64])\n",
      "torch.Size([2, 12, 64])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([3072, 768])\n",
      "torch.Size([3072])\n",
      "torch.Size([768, 3072])\n",
      "torch.Size([768])\n",
      "torch.Size([768, 12, 64])\n",
      "torch.Size([768, 12, 64])\n",
      "torch.Size([768, 12, 64])\n",
      "torch.Size([768, 12, 64])\n",
      "torch.Size([768, 12, 64])\n",
      "torch.Size([12, 64])\n",
      "torch.Size([12, 64])\n",
      "torch.Size([12, 64])\n",
      "torch.Size([2, 12, 64])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([3072, 768])\n",
      "torch.Size([3072])\n",
      "torch.Size([768, 3072])\n",
      "torch.Size([768])\n",
      "torch.Size([768, 12, 64])\n",
      "torch.Size([768, 12, 64])\n",
      "torch.Size([768, 12, 64])\n",
      "torch.Size([768, 12, 64])\n",
      "torch.Size([768, 12, 64])\n",
      "torch.Size([12, 64])\n",
      "torch.Size([12, 64])\n",
      "torch.Size([12, 64])\n",
      "torch.Size([2, 12, 64])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([3072, 768])\n",
      "torch.Size([3072])\n",
      "torch.Size([768, 3072])\n",
      "torch.Size([768])\n",
      "torch.Size([768, 12, 64])\n",
      "torch.Size([768, 12, 64])\n",
      "torch.Size([768, 12, 64])\n",
      "torch.Size([768, 12, 64])\n",
      "torch.Size([768, 12, 64])\n",
      "torch.Size([12, 64])\n",
      "torch.Size([12, 64])\n",
      "torch.Size([12, 64])\n",
      "torch.Size([2, 12, 64])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([3072, 768])\n",
      "torch.Size([3072])\n",
      "torch.Size([768, 3072])\n",
      "torch.Size([768])\n",
      "torch.Size([768, 12, 64])\n",
      "torch.Size([768, 12, 64])\n",
      "torch.Size([768, 12, 64])\n",
      "torch.Size([768, 12, 64])\n",
      "torch.Size([768, 12, 64])\n",
      "torch.Size([12, 64])\n",
      "torch.Size([12, 64])\n",
      "torch.Size([12, 64])\n",
      "torch.Size([2, 12, 64])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([3072, 768])\n",
      "torch.Size([3072])\n",
      "torch.Size([768, 3072])\n",
      "torch.Size([768])\n",
      "torch.Size([768, 12, 64])\n",
      "torch.Size([768, 12, 64])\n",
      "torch.Size([768, 12, 64])\n",
      "torch.Size([768, 12, 64])\n",
      "torch.Size([768, 12, 64])\n",
      "torch.Size([12, 64])\n",
      "torch.Size([12, 64])\n",
      "torch.Size([12, 64])\n",
      "torch.Size([2, 12, 64])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([3072, 768])\n",
      "torch.Size([3072])\n",
      "torch.Size([768, 3072])\n",
      "torch.Size([768])\n",
      "torch.Size([768, 12, 64])\n",
      "torch.Size([768, 12, 64])\n",
      "torch.Size([768, 12, 64])\n",
      "torch.Size([768, 12, 64])\n",
      "torch.Size([768, 12, 64])\n",
      "torch.Size([12, 64])\n",
      "torch.Size([12, 64])\n",
      "torch.Size([12, 64])\n",
      "torch.Size([2, 12, 64])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([3072, 768])\n",
      "torch.Size([3072])\n",
      "torch.Size([768, 3072])\n",
      "torch.Size([768])\n",
      "torch.Size([768, 12, 64])\n",
      "torch.Size([768, 12, 64])\n",
      "torch.Size([768, 12, 64])\n",
      "torch.Size([768, 12, 64])\n",
      "torch.Size([768, 12, 64])\n",
      "torch.Size([12, 64])\n",
      "torch.Size([12, 64])\n",
      "torch.Size([12, 64])\n",
      "torch.Size([2, 12, 64])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([3072, 768])\n",
      "torch.Size([3072])\n",
      "torch.Size([768, 3072])\n",
      "torch.Size([768])\n",
      "torch.Size([768, 12, 64])\n",
      "torch.Size([768, 12, 64])\n",
      "torch.Size([768, 12, 64])\n",
      "torch.Size([768, 12, 64])\n",
      "torch.Size([768, 12, 64])\n",
      "torch.Size([12, 64])\n",
      "torch.Size([12, 64])\n",
      "torch.Size([12, 64])\n",
      "torch.Size([2, 12, 64])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([3072, 768])\n",
      "torch.Size([3072])\n",
      "torch.Size([768, 3072])\n",
      "torch.Size([768])\n",
      "torch.Size([768, 12, 64])\n",
      "torch.Size([768, 12, 64])\n",
      "torch.Size([768, 12, 64])\n",
      "torch.Size([768, 12, 64])\n",
      "torch.Size([768, 12, 64])\n",
      "torch.Size([12, 64])\n",
      "torch.Size([12, 64])\n",
      "torch.Size([12, 64])\n",
      "torch.Size([2, 12, 64])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([3072, 768])\n",
      "torch.Size([3072])\n",
      "torch.Size([768, 3072])\n",
      "torch.Size([768])\n",
      "torch.Size([768, 12, 64])\n",
      "torch.Size([768, 12, 64])\n",
      "torch.Size([768, 12, 64])\n",
      "torch.Size([768, 12, 64])\n",
      "torch.Size([768, 12, 64])\n",
      "torch.Size([12, 64])\n",
      "torch.Size([12, 64])\n",
      "torch.Size([12, 64])\n",
      "torch.Size([2, 12, 64])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([3072, 768])\n",
      "torch.Size([3072])\n",
      "torch.Size([768, 3072])\n",
      "torch.Size([768])\n",
      "torch.Size([768, 12, 64])\n",
      "torch.Size([768, 12, 64])\n",
      "torch.Size([768, 12, 64])\n",
      "torch.Size([768, 12, 64])\n",
      "torch.Size([768, 12, 64])\n",
      "torch.Size([12, 64])\n",
      "torch.Size([12, 64])\n",
      "torch.Size([12, 64])\n",
      "torch.Size([2, 12, 64])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([3072, 768])\n",
      "torch.Size([3072])\n",
      "torch.Size([768, 3072])\n",
      "torch.Size([768])\n",
      "torch.Size([768, 768])\n",
      "torch.Size([768])\n",
      "torch.Size([2, 768])\n",
      "torch.Size([2])\n",
      "该网络参数总量为： 117310466\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "from tqdm.auto import tqdm\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch.utils.data import DataLoader, RandomSampler, SequentialSampler, TensorDataset\n",
    "from transformers import XLNetTokenizer, XLNetForSequenceClassification, AdamW\n",
    "model = XLNetForSequenceClassification.from_pretrained(\"xlnet-base-cased\")\n",
    "param_num = 0\n",
    "for param in model.parameters():\n",
    "    param_num += torch.numel(param)\n",
    "    print(param.shape)\n",
    "print('该网络参数总量为：',param_num)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "django5",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
